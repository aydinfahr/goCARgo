import os
import re
from transformers import pipeline
from langdetect import detect, DetectorFactory
from dotenv import load_dotenv
from textblob import TextBlob

# Ensure consistent language detection results
DetectorFactory.seed = 0

# ‚úÖ Load Hugging Face AI Models (Explicitly Specified to Remove Warnings)
sentiment_analysis_model = pipeline(
    "sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment"
)  # ‚úÖ Multi-language sentiment analysis model

hate_speech_model = pipeline(
    "text-classification", model="facebook/roberta-hate-speech-dynabench-r4-target"
)  # ‚úÖ Hate speech detection

# ‚úÖ Multi-language Banned Words Dictionary
BANNED_WORDS = {
    "en": {"fuck", "shit", "asshole", "bitch", "bastard", "nazi", "racist", "slur"},
    "tr": {"siktir", "orospu", "amk", "pezevenk", "salak", "gerizekalƒ±"},
    "es": {"puta", "mierda", "gilipollas", "malparido"},
    "fr": {"merde", "salope", "encul√©"},
    "de": {"schei√üe", "hurensohn"},
    "it": {"stronzo", "cazzo"},
    "ru": {"–±–ª—è–¥—å", "—Å—É–∫–∞"},
    "ar": {"ŸÑÿπŸÜÿ©", "ŸÇÿ∞ÿ±"}
}

def analyze_sentiment(text: str) -> float:
    """
    ‚úÖ Analyzes sentiment using TextBlob (Backup Method).
    - Returns a polarity score:
      - Positive (> 0) = Positive sentiment
      - 0 = Neutral
      - Negative (< 0) = Negative sentiment
    """
    blob = TextBlob(text)
    return blob.sentiment.polarity  # ‚úÖ Returns polarity score

def ai_moderation(text: str) -> dict:
    """
    ‚úÖ Uses Free AI Models (Hugging Face) to Detect:
    - Hate speech
    - Offensive language
    - Extremely negative sentiment
    - Multi-language banned words check
    - Returns a dictionary with "flagged" (True/False) and "moderation_reason".
    """

    print(f"üîç Moderating text: {text}")  # ‚úÖ Debugging log

    try:
        detected_lang = detect(text)
        if len(text.split()) < 3:  # ‚úÖ langdetect fails for very short texts
            detected_lang = "en"  # Assume English for short inputs
    except Exception:
        detected_lang = "en"  # ‚úÖ Default to English if detection fails

    print(f"üåç Detected Language: {detected_lang}")  # ‚úÖ Debugging log

    # ‚úÖ Step 1: Check for banned words (case insensitive)
    words = set(re.findall(r"\b\w+\b", text.lower()))
    banned_words = BANNED_WORDS.get(detected_lang, set())

    if words & banned_words:
        print(f"‚ùå Blocked: Contains banned words ({detected_lang}): {words & banned_words}")
        return {
            "flagged": True,
            "moderation_reason": f"Contains banned words in {detected_lang}"
        }

    # ‚úÖ Step 2: AI Hate Speech Detection (Ignore "mild" insults)
    hate_result = hate_speech_model(text)
    print(f"üßê Hate Speech Model Output: {hate_result}")  # ‚úÖ Debugging log

    if hate_result[0]["label"] == "HATE_SPEECH":  # ‚úÖ Ignore "INSULT" category
        print(f"‚ùå Blocked: AI detected hate speech: {text}")
        return {
            "flagged": True,
            "moderation_reason": "Detected hate speech"
        }

    # ‚úÖ Step 3: AI Sentiment Analysis (Allow Mild Negativity)
    sentiment_result = sentiment_analysis_model(text)
    sentiment_label = sentiment_result[0]["label"]

    # ‚úÖ Convert sentiment label to score (5=Positive, 1=Negative)
    sentiment_mapping = {"1 star": -1.0, "2 stars": -0.5, "3 stars": 0, "4 stars": 0.5, "5 stars": 1.0}
    sentiment_score = sentiment_mapping.get(sentiment_label, 0)

    print(f"üßê Sentiment Score: {sentiment_score}")  # ‚úÖ Debugging log

    if sentiment_score < -0.9:  # ‚úÖ Adjusted threshold for better moderation
        print(f"‚ùå Blocked: Extreme negativity detected in text: {text}")
        return {
            "flagged": True,
            "moderation_reason": "Extreme negative sentiment detected"
        }

    print(f"‚úÖ Passed moderation: {text}")  # ‚úÖ Debugging log
    return {
        "flagged": False,
        "moderation_reason": "OK"
    }  # ‚úÖ If no issues found, return False (text is safe)


-------------------------------------------------------------------------------------------------------------

import os
import re
from transformers import pipeline
from langdetect import detect, DetectorFactory
from dotenv import load_dotenv
from textblob import TextBlob

# Ensure consistent language detection results
DetectorFactory.seed = 0

# ‚úÖ Load Hugging Face AI Models (Free & No API Key Needed)
sentiment_analysis_model = pipeline(
    "sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment"
)  # ‚úÖ Multi-language sentiment analysis model

hate_speech_model = pipeline(
    "text-classification", model="facebook/roberta-hate-speech-dynabench-r4-target"
)  # ‚úÖ Hate speech detection

# ‚úÖ Multi-language Banned Words Dictionary
BANNED_WORDS = {
    "en": {"fuck", "shit", "asshole", "bitch", "bastard", "nazi", "racist", "offensive", "slur"},
    "tr": {"siktir", "orospu", "amk", "pezevenk", "salak", "gerizekalƒ±"},
    "es": {"puta", "mierda", "gilipollas", "malparido"},
    "fr": {"merde", "salope", "encul√©"},
    "de": {"schei√üe", "hurensohn"},
    "it": {"stronzo", "cazzo"},
    "ru": {"–±–ª—è–¥—å", "—Å—É–∫–∞"},
    "ar": {"ŸÑÿπŸÜÿ©", "ŸÇÿ∞ÿ±"}
}

def analyze_sentiment(text: str) -> float:
    """
    ‚úÖ Analyzes sentiment using TextBlob (Backup Method).
    - Returns a polarity score:
      - Positive (> 0) = Positive sentiment
      - 0 = Neutral
      - Negative (< 0) = Negative sentiment
    """
    blob = TextBlob(text)
    return blob.sentiment.polarity  # ‚úÖ Returns polarity score

def ai_moderation(text: str) -> dict:
    """
    ‚úÖ Uses Free AI Models (Hugging Face) to Detect:
    - Hate speech
    - Offensive language
    - Extremely negative sentiment
    - Multi-language banned words check
    - Returns a dictionary with "flagged" (True/False) and "moderation_reason".
    """

    try:
        detected_lang = detect(text)
    except Exception:
        detected_lang = "en"  # ‚úÖ Default to English if detection fails

    # ‚úÖ Step 1: Check for manual banned words (case insensitive)
    words = set(re.findall(r"\b\w+\b", text.lower()))  # Extract words from text
    banned_words = BANNED_WORDS.get(detected_lang, set())

    if words & banned_words:  # ‚úÖ Check for intersection
        return {
            "flagged": True,
            "moderation_reason": f"Contains banned words in {detected_lang}"
        }

    # ‚úÖ Step 2: AI Hate Speech Detection (Ignore "mild" cases)
    hate_result = hate_speech_model(text)
    if hate_result[0]["label"] in ["HATE_SPEECH", "INSULT"]:
        return {
            "flagged": True,
            "moderation_reason": "Detected hate speech or strong insults"
        }

    # ‚úÖ Step 3: AI Sentiment Analysis (Allow Mild Negativity)
    sentiment_result = sentiment_analysis_model(text)
    sentiment_label = sentiment_result[0]["label"]

    # ‚úÖ Convert sentiment label to score (5=Positive, 1=Negative)
    sentiment_mapping = {"1 star": -1.0, "2 stars": -0.5, "3 stars": 0, "4 stars": 0.5, "5 stars": 1.0}
    sentiment_score = sentiment_mapping.get(sentiment_label, 0)

    if sentiment_score < -0.8:  # ‚úÖ Adjusted threshold for better moderation
        return {
            "flagged": True,
            "moderation_reason": "Extreme negative sentiment detected"
        }

    return {
        "flagged": False,
        "moderation_reason": "OK"
    }  # ‚úÖ If no issues found, return False (text is safe)


----------------------------------------------------------------------------------------------------------------

import os
import re
from transformers import pipeline
from langdetect import detect
from dotenv import load_dotenv
from textblob import TextBlob

# ‚úÖ Load Hugging Face AI Models (Free & No API Key Needed)
sentiment_analysis_model = pipeline("sentiment-analysis")  # AI Model for Sentiment Analysis
hate_speech_model = pipeline("text-classification", model="facebook/roberta-hate-speech-dynabench-r4-target")

# ‚úÖ Multi-language Banned Words Dictionary
BANNED_WORDS = {
    "en": {"fuck", "shit", "asshole", "bitch", "bastard", "nazi", "racist", "offensive", "slur", "hate"},
    "tr": {"siktir", "orospu", "amk", "pezevenk", "salak", "gerizekalƒ±"},
    "es": {"puta", "mierda", "gilipollas", "malparido"},
    "fr": {"merde", "salope", "encul√©"},
    "de": {"schei√üe", "hurensohn"},
    "it": {"stronzo", "cazzo"},
    "ru": {"–±–ª—è–¥—å", "—Å—É–∫–∞"},
    "ar": {"ŸÑÿπŸÜÿ©", "ŸÇÿ∞ÿ±"}
}

def analyze_sentiment(text: str) -> float:
    """
    ‚úÖ Analyzes sentiment using TextBlob (Backup Method).
    - Returns a polarity score:
      - Positive (> 0) = Positive sentiment
      - 0 = Neutral
      - Negative (< 0) = Negative sentiment
    """
    blob = TextBlob(text)
    return blob.sentiment.polarity  # ‚úÖ Returns polarity score

def ai_moderation(text: str) -> dict:
    """
    ‚úÖ Uses Free AI Models (Hugging Face) to Detect:
    - Hate speech
    - Offensive language
    - Extremely negative sentiment
    - Multi-language banned words check
    - Returns a dictionary with "flagged" (True/False) and "moderation_reason".
    """

    try:
        detected_lang = detect(text)  # ‚úÖ Detect the language
    except:
        detected_lang = "en"  # Default to English if detection fails

    # ‚úÖ Step 1: Check for manual banned words (case insensitive)
    words = set(re.findall(r"\b\w+\b", text.lower()))  # Extract words from text
    banned_words = BANNED_WORDS.get(detected_lang, set())  # Get banned words for detected language

    if words & banned_words:  # ‚úÖ Check for intersection
        return {
            "flagged": True,
            "moderation_reason": f"Contains banned words in {detected_lang}"
        }

    # ‚úÖ Step 2: AI Hate Speech Detection (Ignore "mild" cases)
    hate_result = hate_speech_model(text)
    if hate_result[0]["label"] in ["HATE_SPEECH", "INSULT"]:  # Ignore mild offensive text
        return {
            "flagged": True,
            "moderation_reason": "Detected hate speech or strong insults"
        }

    # ‚úÖ Step 3: AI Sentiment Analysis (Only Block Extremely Negative Sentiment)
    sentiment_result = sentiment_analysis_model(text)
    if sentiment_result[0]["label"] == "NEGATIVE":
        sentiment_score = analyze_sentiment(text)  # Check exact negativity score
        if sentiment_score < -0.6:  # Allow mild negativity but block extreme cases
            return {
                "flagged": True,
                "moderation_reason": "Extreme negative sentiment detected"
            }

    return {
        "flagged": False,
        "moderation_reason": "OK"
    }  # ‚úÖ If no issues found, return False (text is safe)


